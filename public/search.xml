<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>ubuntu jupyternotebook添加keanel被拒绝</title>
      <link href="/2020/07/29/jupyternotebook%E6%B7%BB%E5%8A%A0keanel%E8%A2%AB%E6%8B%92%E7%BB%9D/"/>
      <url>/2020/07/29/jupyternotebook%E6%B7%BB%E5%8A%A0keanel%E8%A2%AB%E6%8B%92%E7%BB%9D/</url>
      
        <content type="html"><![CDATA[<h1 id="Errno-13-Permission-denied-’-usr-local-share-jupyter’"><a href="#Errno-13-Permission-denied-’-usr-local-share-jupyter’" class="headerlink" title="[Errno 13] Permission denied:’/usr/local/share/jupyter’"></a>[Errno 13] Permission denied:’/usr/local/share/jupyter’</h1><h2 id="1-问题描述"><a href="#1-问题描述" class="headerlink" title="1.问题描述"></a>1.问题描述</h2><p>当我们使用conda创建虚拟环境后，keanel不会自动添加到jupyter notebook的keanel列表当中，这时候就需要我们通过命令手动添加，Windows下的操作命令如下：</p><a id="more"></a><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">conda activate mmd2 <span class="comment"># 激活环境</span></span><br><span class="line">conda install ipykernel <span class="comment"># 安装必要插件</span></span><br><span class="line">python -m ipykernel install --name mmd2</span><br></pre></td></tr></table></figure><p>但是相同的情况在Ubuntu环境下使用的话，会出现 <code>[Errno 13] Permission denied:&#39;/usr/local/share/jupyter</code>的错误，如图一所示：</p><p><img src="https://img-blog.csdnimg.cn/20200729091057104.png#pic_center" alt=""></p><center><font size = 3>图1 问题图片</font></center>## 2.问题解决在安装命令里添加`--usr`即可解决，命令如下：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m ipykernel install --usr --name mmd2</span><br></pre></td></tr></table></figure>结果图如下所示：<p><img src="https://img-blog.csdnimg.cn/2020072909115154.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ubuntu </tag>
            
            <tag> jupyternotebook </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>修改json内容</title>
      <link href="/2020/07/28/json%E4%BF%AE%E6%94%B9%E5%86%85%E5%AE%B9/"/>
      <url>/2020/07/28/json%E4%BF%AE%E6%94%B9%E5%86%85%E5%AE%B9/</url>
      
        <content type="html"><![CDATA[<h1 id="修改json内容"><a href="#修改json内容" class="headerlink" title="修改json内容"></a>修改json内容</h1><h2 id="1-问题描述"><a href="#1-问题描述" class="headerlink" title="1. 问题描述"></a>1. 问题描述</h2><p>当时用labelme标注图片后，又对文件进行了重命名，发现<code>imagePath</code>和重命名的文件名不一致，这样在制作coco数据集时会出现报错的情况，因此需要对<code>imagePath</code>也进行更新。</p><a id="more"></a><p><img src="https://img-blog.csdnimg.cn/20200728220942334.png#pic_center" alt=""></p><center> <font size = 3>图1. 问题图片.png</font></center><h2 id="2-程序操作"><a href="#2-程序操作" class="headerlink" title="2.程序操作"></a>2.程序操作</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#导入程序包</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="comment">#定位json所在的文件夹</span></span><br><span class="line">file_json=<span class="string">'D:\\LocalGithub\\mmdetection2.0\\data\\dataB\\coco\\test2014'</span> </span><br><span class="line"><span class="comment">#定义操作函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">change_json</span><span class="params">(path)</span>:</span></span><br><span class="line">    files=os.listdir(path)</span><br><span class="line">    <span class="comment">#os.listdir() 方法用于返回指定的文件夹包含的文件或文件夹的名字的列表</span></span><br><span class="line">    <span class="keyword">for</span> file <span class="keyword">in</span> files: </span><br><span class="line">        dir=os.path.join(path,file)</span><br><span class="line">        <span class="comment"># os.path.join()，将join()里面得参数拼接成一个完整得路径。</span></span><br><span class="line">        <span class="comment"># 检查是否为文件夹，如果是，则递归</span></span><br><span class="line">        <span class="keyword">if</span> os.path.isdir(dir):</span><br><span class="line">            chang_json(dir)</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        file_split=file.split(<span class="string">'.'</span>)</span><br><span class="line">        <span class="comment">#file.split将file列表数据以"."分割，并赋值给file_split</span></span><br><span class="line">        <span class="keyword">if</span> file_split[<span class="number">-1</span>] == <span class="string">"json"</span>:</span><br><span class="line">            str=<span class="string">""</span>.join(file_split[<span class="number">0</span>])+<span class="string">".jpg"</span> <span class="comment"># 定义要更改的文件名</span></span><br><span class="line">            <span class="keyword">with</span> open(path+<span class="string">'\\'</span>+file,<span class="string">'rb'</span>) <span class="keyword">as</span> load_f: </span><br><span class="line">            <span class="comment">#定义为只读模式，并定义名称为f</span></span><br><span class="line">                params = json.load(load_f)</span><br><span class="line">                <span class="comment">#加载json文件中的内容给params</span></span><br><span class="line">                load_f.close() <span class="comment"># 关闭文件</span></span><br><span class="line">            <span class="keyword">with</span> open(path+<span class="string">'\\'</span>+file,<span class="string">'w'</span>) <span class="keyword">as</span> dump_f:</span><br><span class="line">            <span class="comment">#定义为写入模式，并定义名称为f</span></span><br><span class="line">                print(str) <span class="comment"># 查看要写入的名称</span></span><br><span class="line">                params[<span class="string">'imagePath'</span>] = str <span class="comment"># 更改参数</span></span><br><span class="line">                json.dump(params,dump_f) <span class="comment"># 将params写入文件</span></span><br><span class="line">                dump_f.close() <span class="comment">#关闭文件</span></span><br></pre></td></tr></table></figure><blockquote><p>到此文件就更新完成了，只不过原先json文件里有换行符，更新后没有了影响观看，但是不影响正常使用。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> json </tag>
            
            <tag> io </tag>
            
            <tag> labelme </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【MMDetection】(二):getting_started.md</title>
      <link href="/2020/06/16/%E3%80%90MMDetection%E3%80%91%E4%BA%8C%20getting-started-md/"/>
      <url>/2020/06/16/%E3%80%90MMDetection%E3%80%91%E4%BA%8C%20getting-started-md/</url>
      
        <content type="html"><![CDATA[<h1 id="Getting-Started-开始使用mmdetection"><a href="#Getting-Started-开始使用mmdetection" class="headerlink" title="Getting Started 开始使用mmdetection"></a>Getting Started 开始使用mmdetection</h1><p>This page provides basic tutorials about the usage of MMDetection.<br>For installation instructions, please see <a href="install.md">install.md</a>.<br>//本页提供有关MMDetection用法的基本教程。<br>//关于有关安装说明，请查看文件<a href="install.md">install.md</a>.</p><a id="more"></a><h2 id="Prepare-datasets-准备数据"><a href="#Prepare-datasets-准备数据" class="headerlink" title="Prepare datasets 准备数据"></a>Prepare datasets 准备数据</h2><p>It is recommended to symlink the dataset root to <code>$MMDETECTION/data</code>.<br>If your folder structure is different, you may need to change the corresponding paths in config files.<br>//建议将数据集根目录链接到<code>$MMDETECTION/data</code>。<br>//如果您的文件夹结构不同，则可能需要更改配置文件中的相应路径。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">mmdetection</span><br><span class="line">├── mmdet</span><br><span class="line">├── tools</span><br><span class="line">├── configs</span><br><span class="line">├── data</span><br><span class="line">│   ├── coco</span><br><span class="line">│   │   ├── annotations</span><br><span class="line">│   │   ├── train2017</span><br><span class="line">│   │   ├── val2017</span><br><span class="line">│   │   ├── test2017</span><br><span class="line">│   ├── cityscapes</span><br><span class="line">│   │   ├── annotations</span><br><span class="line">│   │   ├── leftImg8bit</span><br><span class="line">│   │   │   ├── train</span><br><span class="line">│   │   │   ├── val</span><br><span class="line">│   │   ├── gtFine</span><br><span class="line">│   │   │   ├── train</span><br><span class="line">│   │   │   ├── val</span><br><span class="line">│   ├── VOCdevkit</span><br><span class="line">│   │   ├── VOC2007</span><br><span class="line">│   │   ├── VOC2012</span><br></pre></td></tr></table></figure><p>The cityscapes annotations have to be converted into the coco format using <code>tools/convert_datasets/cityscapes.py</code>:<br>// cityspaces标注必须使用以下命令转换为coco格式：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install cityscapesscripts</span><br><span class="line">python tools/convert_datasets/cityscapes.py ./data/cityscapes --nproc 8 --out-dir ./data/cityscapes/annotations</span><br></pre></td></tr></table></figure><p>Currently the config files in <code>cityscapes</code> use COCO pre-trained weights to initialize.<br>You could download the pre-trained models in advance if network is unavailable or slow, otherwise it would cause errors at the beginning of training.<br>//当前，“ cityscapes”中的配置文件使用COCO预训练的权重进行初始化。<br>//如果网络不可用或速度较慢，您可以提前下载经过预先训练的模型，否则会在训练开始时导致错误。<br>For using custom datasets, please refer to <a href="tutorials/new_dataset.md">Tutorials 2: Adding New Dataset</a>.<br>//有关使用自定义数据集的信息，请参阅<a href="tutorials/new_dataset.md">Tutorials 2: Adding New Dataset</a>。</p><h2 id="Inference-with-pretrained-models使用预训连模型进行推理"><a href="#Inference-with-pretrained-models使用预训连模型进行推理" class="headerlink" title="Inference with pretrained models使用预训连模型进行推理"></a>Inference with pretrained models使用预训连模型进行推理</h2><p>We provide testing scripts to evaluate a whole dataset (COCO, PASCAL VOC, Cityscapes, etc.),<br>and also some high-level apis for easier integration to other projects.<br>//我们提供测试脚本来评估整个数据集（COCO，PASCAL VOC，Cityscapes等），<br>//以及一些高级api，以便更轻松地集成到其他项目。</p><h3 id="Test-a-dataset-测试一个数据集"><a href="#Test-a-dataset-测试一个数据集" class="headerlink" title="Test a dataset 测试一个数据集"></a>Test a dataset 测试一个数据集</h3><ul><li>single GPU 单GPU</li><li>single node multiple GPU 单节点多GPU</li><li>multiple node 多节点</li></ul><p>You can use the following commands to test a dataset.<br>// 你可以使用以下命令来测试数据集</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> single-gpu testing 单gpu测试</span></span><br><span class="line">python tools/test.py $&#123;CONFIG_FILE&#125; $&#123;CHECKPOINT_FILE&#125; [--out $&#123;RESULT_FILE&#125;] [--eval $&#123;EVAL_METRICS&#125;] [--show]</span><br><span class="line">    # CONFIG_FILE：初始化文件</span><br><span class="line">    # RESULT_FILE：结果文件</span><br><span class="line">    # EVAL_METRICS: 测量参数</span><br><span class="line">    # --show：是否显示</span><br><span class="line"><span class="meta">#</span><span class="bash"> multi-gpu testing 多gpu测试</span></span><br><span class="line">./tools/dist_test.sh $&#123;CONFIG_FILE&#125; $&#123;CHECKPOINT_FILE&#125; $&#123;GPU_NUM&#125; [--out $&#123;RESULT_FILE&#125;] [--eval $&#123;EVAL_METRICS&#125;]</span><br><span class="line">    # CONFIG_FILE：初始化文件</span><br><span class="line">    # GPU_NUM：GPU数量</span><br><span class="line">    # RESULT_FILE：结果文件</span><br><span class="line">    # EVAL_METRICS: 测量参数</span><br></pre></td></tr></table></figure><p>Optional arguments: // 可选参数</p><ul><li><code>RESULT_FILE</code>: Filename of the output results in pickle format. If not specified, the results will not be saved to a file. # 输出结果的文件名采用pickle格式。 如果未指定，结果将不会保存到文件中。</li><li><code>EVAL_METRICS</code>: Items to be evaluated on the results. Allowed values depend on the dataset, e.g., <code>proposal_fast</code>, <code>proposal</code>, <code>bbox</code>, <code>segm</code> are available for COCO, <code>mAP</code>, <code>recall</code> for PASCAL VOC. Cityscapes could be evaluated by <code>cityscapes</code> as well as all COCO metrics. # 测量的指标参数。coco格式数据集可以测量： <code>proposal_fast</code>, <code>proposal</code>, <code>bbox</code>, <code>segm</code>；VOC格式数据集可以测量：<code>mAP</code>, <code>recall</code>；Cityspaces格式数据集可以测试：<code>proposal_fast</code>, <code>proposal</code>, <code>bbox</code>, <code>segm</code>，<code>cityspaces</code>。</li><li><code>--show</code>: If specified, detection results will be plotted on the images and shown in a new window. It is only applicable to single GPU testing and used for debugging and visualization. Please make sure that GUI is available in your environment, otherwise you may encounter the error like <code>cannot connect to X server</code>.# 如果指定，检测结果将绘制在图像上并显示在新窗口中。 它仅适用于单个GPU测试，并用于调试和可视化。 请确保您的环境中可以使用GUI，否则您可能会遇到类似<code>cannot connect to X server</code>的错误。</li><li><code>--show-dir</code>: If specified, detection results will be plotted on the images and saved to the specified directory. It is only applicable to single GPU testing and used for debugging and visualization. You do NOT need a GUI available in your environment for using this option.#如果指定，检测结果将绘制在图像上并保存到指定目录。 它仅适用于单个GPU测试，并用于调试和可视化。 您不需要环境中可用的GUI即可使用此选项。</li><li><code>--show-score-thr</code>: If specified, detections with score below this threshold will be removed.#如果指定，则分数低于此阈值的检测将被删除。</li></ul><p>Examples:#例如</p><p>Assume that you have already downloaded the checkpoints to the directory <code>checkpoints/</code>.<br>#确保你事先已经把模型下载到了<code>checkpoints/</code>文件夹中。</p><ol><li><p>Test Faster R-CNN and visualize the results. Press any key for the next image.<br>#1.测试Faster R-CNN并显示结果。按任意按键查看下一张图片</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">python tools/test.py configs/faster_rcnn_r50_fpn_1x_coco.py \</span><br><span class="line">    checkpoints/faster_rcnn_r50_fpn_1x_20181010-3d1b3351.pth \</span><br><span class="line">    --show</span><br></pre></td></tr></table></figure></li><li><p>Test Faster R-CNN and save the painted images for latter visualization.<br>#2.测试Faster R-CNN并保存识别后的图片。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">python tools/test.py configs/faster_rcnn_r50_fpn_1x.py \</span><br><span class="line">    checkpoints/faster_rcnn_r50_fpn_1x_20181010-3d1b3351.pth \</span><br><span class="line">    --show-dir faster_rcnn_r50_fpn_1x_results</span><br></pre></td></tr></table></figure></li><li><p>Test Faster R-CNN on PASCAL VOC (without saving the test results) and evaluate the mAP.<br>#3.测试Faster R-CNN(不保存结果)，并测试mAP</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">python tools/test.py configs/pascal_voc/faster_rcnn_r50_fpn_1x_voc.py \</span><br><span class="line">    checkpoints/SOME_CHECKPOINT.pth \</span><br><span class="line">    --eval mAP</span><br></pre></td></tr></table></figure></li><li><p>Test Mask R-CNN with 8 GPUs, and evaluate the bbox and mask AP.<br>#4.用8张GPU测试Mask R-CNN，评价指标 bbox和mask AP</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">./tools/dist_test.sh configs/mask_rcnn_r50_fpn_1x_coco.py \</span><br><span class="line">    checkpoints/mask_rcnn_r50_fpn_1x_20181010-069fa190.pth \</span><br><span class="line">    8 --out results.pkl --eval bbox segm</span><br></pre></td></tr></table></figure></li><li><p>Test Mask R-CNN with 8 GPUs, and evaluate the <strong>classwise</strong> bbox and mask AP.<br>#5.用8张GPU测试Mask R-CNN,评价指标 <strong>classwise</strong>（每个类别） bbox 和 mask AP</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">./tools/dist_test.sh configs/mask_rcnn_r50_fpn_1x_coco.py \</span><br><span class="line">    checkpoints/mask_rcnn_r50_fpn_1x_20181010-069fa190.pth \</span><br><span class="line">    8 --out results.pkl --eval bbox segm --options "classwise=True"</span><br></pre></td></tr></table></figure></li><li><p>Test Mask R-CNN on COCO test-dev with 8 GPUs, and generate the json file to be submit to the official evaluation server.<br>#用8张GPU测试Mask R-CNN,生成json文件，并提交给官方服务器。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">./tools/dist_test.sh configs/mask_rcnn_r50_fpn_1x_coco.py \</span><br><span class="line">    checkpoints/mask_rcnn_r50_fpn_1x_20181010-069fa190.pth \</span><br><span class="line">    8 --format-only --options "jsonfile_prefix=./mask_rcnn_test-dev_results"</span><br></pre></td></tr></table></figure></li></ol><p>You will get two json files <code>mask_rcnn_test-dev_results.bbox.json</code> and <code>mask_rcnn_test-dev_results.segm.json</code>.<br>#你将会得到两个json文件<code>mask_rcnn_test-dev_results.bbox.json</code> 和 <code>mask_rcnn_test-dev_results.segm.json</code>。<br>7. Test Mask R-CNN on Cityscapes test with 8 GPUs, and generate the txt and png files to be submit to the official evaluation server.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">./tools/dist_test.sh configs/cityscapes/mask_rcnn_r50_fpn_1x_cityscapes.py \</span><br><span class="line">    checkpoints/mask_rcnn_r50_fpn_1x_cityscapes_20200227-afe51d5a.pth \</span><br><span class="line">    8  --format-only --options "txtfile_prefix=./mask_rcnn_cityscapes_test_results"</span><br></pre></td></tr></table></figure><p>The generated png and txt would be under <code>./mask_rcnn_cityscapes_test_results</code> directory.</p><h3 id="Image-demo图片测试"><a href="#Image-demo图片测试" class="headerlink" title="Image demo图片测试"></a>Image demo图片测试</h3><p>We provide a demo script to test a single image.<br>#我们提供了一个测试单张图片的文件。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python demo/image_demo.py $&#123;IMAGE_FILE&#125; $&#123;CONFIG_FILE&#125; $&#123;CHECKPOINT_FILE&#125; [--device $&#123;GPU_ID&#125;] [--score-thr $&#123;SCORE_THR&#125;]</span><br></pre></td></tr></table></figure><p>Examples:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">python demo/image_demo.py demo/demo.jpg configs/faster_rcnn_r50_fpn_1x_coco.py \</span><br><span class="line">    checkpoints/faster_rcnn_r50_fpn_1x_20181010-3d1b3351.pth --device cpu</span><br></pre></td></tr></table></figure><h3 id="Webcam-demo网络摄像头测试"><a href="#Webcam-demo网络摄像头测试" class="headerlink" title="Webcam demo网络摄像头测试"></a>Webcam demo网络摄像头测试</h3><p>We provide a webcam demo to illustrate the results.<br>#我们提供了一个网络摄像头演示来说明结果。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python demo/webcam_demo.py $&#123;CONFIG_FILE&#125; $&#123;CHECKPOINT_FILE&#125; [--device $&#123;GPU_ID&#125;] [--camera-id $&#123;CAMERA-ID&#125;] [--score-thr $&#123;SCORE_THR&#125;]</span><br></pre></td></tr></table></figure><p>Examples:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">python demo/webcam_demo.py configs/faster_rcnn_r50_fpn_1x_coco.py \</span><br><span class="line">    checkpoints/faster_rcnn_r50_fpn_1x_20181010-3d1b3351.pth</span><br></pre></td></tr></table></figure><h3 id="High-level-APIs-for-testing-images用于测试图像的高级API"><a href="#High-level-APIs-for-testing-images用于测试图像的高级API" class="headerlink" title="High-level APIs for testing images用于测试图像的高级API"></a>High-level APIs for testing images用于测试图像的高级API</h3><h4 id="Synchronous-interface同步接口"><a href="#Synchronous-interface同步接口" class="headerlink" title="Synchronous interface同步接口"></a>Synchronous interface同步接口</h4><p>Here is an example of building the model and test given images.<br>#这是构建模型并测试给定图像的示例。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> mmdet.apis <span class="keyword">import</span> init_detector, inference_detector</span><br><span class="line"><span class="keyword">import</span> mmcv</span><br><span class="line"></span><br><span class="line">config_file = <span class="string">'configs/faster_rcnn_r50_fpn_1x_coco.py'</span></span><br><span class="line">checkpoint_file = <span class="string">'checkpoints/faster_rcnn_r50_fpn_1x_20181010-3d1b3351.pth'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># build the model from a config file and a checkpoint file</span></span><br><span class="line">model = init_detector(config_file, checkpoint_file, device=<span class="string">'cuda:0'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># test a single image and show the results</span></span><br><span class="line">img = <span class="string">'test.jpg'</span>  <span class="comment"># or img = mmcv.imread(img), which will only load it once</span></span><br><span class="line">result = inference_detector(model, img)</span><br><span class="line"><span class="comment"># visualize the results in a new window</span></span><br><span class="line">model.show_result(img, result)</span><br><span class="line"><span class="comment"># or save the visualization results to image files</span></span><br><span class="line">model.show_result(img, result, out_file=<span class="string">'result.jpg'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># test a video and show the results</span></span><br><span class="line">video = mmcv.VideoReader(<span class="string">'video.mp4'</span>)</span><br><span class="line"><span class="keyword">for</span> frame <span class="keyword">in</span> video:</span><br><span class="line">    result = inference_detector(model, frame)</span><br><span class="line">    model.show_result(frame, result, wait_time=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>A notebook demo can be found in <a href="https://github.com/open-mmlab/mmdetection/blob/master/demo/inference_demo.ipynb" target="_blank" rel="noopener">demo/inference_demo.ipynb</a>.</p><h4 id="Asynchronous-interface-supported-for-Python-3-7"><a href="#Asynchronous-interface-supported-for-Python-3-7" class="headerlink" title="Asynchronous interface - supported for Python 3.7+"></a>Asynchronous interface - supported for Python 3.7+</h4><p>#异步接口-支持Python3.7+</p><p>Async interface allows not to block CPU on GPU bound inference code and enables better CPU/GPU utilization for single threaded application. Inference can be done concurrently either between different input data samples or between different models of some inference pipeline.<br>#异步接口允许不阻塞GPU绑定的推理代码上的CPU，并为单线程应用程序提供更好的CPU/GPU利用率。可以在不同的输入数据样本之间或某个推理管道的不同模型之间并发地进行推理。<br>See <code>tests/async_benchmark.py</code> to compare the speed of synchronous and asynchronous interfaces.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> mmdet.apis <span class="keyword">import</span> init_detector, async_inference_detector</span><br><span class="line"><span class="keyword">from</span> mmdet.utils.contextmanagers <span class="keyword">import</span> concurrent</span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    config_file = <span class="string">'configs/faster_rcnn_r50_fpn_1x_coco.py'</span></span><br><span class="line">    checkpoint_file = <span class="string">'checkpoints/faster_rcnn_r50_fpn_1x_20181010-3d1b3351.pth'</span></span><br><span class="line">    device = <span class="string">'cuda:0'</span></span><br><span class="line">    model = init_detector(config_file, checkpoint=checkpoint_file, device=device)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># queue is used for concurrent inference of multiple images</span></span><br><span class="line">    streamqueue = asyncio.Queue()</span><br><span class="line">    <span class="comment"># queue size defines concurrency level</span></span><br><span class="line">    streamqueue_size = <span class="number">3</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> range(streamqueue_size):</span><br><span class="line">        streamqueue.put_nowait(torch.cuda.Stream(device=device))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># test a single image and show the results</span></span><br><span class="line">    img = <span class="string">'test.jpg'</span>  <span class="comment"># or img = mmcv.imread(img), which will only load it once</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">async</span> <span class="keyword">with</span> concurrent(streamqueue):</span><br><span class="line">        result = <span class="keyword">await</span> async_inference_detector(model, img)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># visualize the results in a new window</span></span><br><span class="line">    model.show_result(img, result)</span><br><span class="line">    <span class="comment"># or save the visualization results to image files</span></span><br><span class="line">    model.show_result(img, result, out_file=<span class="string">'result.jpg'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">asyncio.run(main())</span><br></pre></td></tr></table></figure><h2 id="Train-a-model训练一个模型"><a href="#Train-a-model训练一个模型" class="headerlink" title="Train a model训练一个模型"></a>Train a model训练一个模型</h2><p>MMDetection implements distributed training and non-distributed training,<br>which uses <code>MMDistributedDataParallel</code> and <code>MMDataParallel</code> respectively.<br>#MMDetection实施分布式培训和非分布式培训，<br>#分别使用<code>MMDistributedDataParallel</code>和<code>MMDataParallel</code>。<br>All outputs (log files and checkpoints) will be saved to the working directory,<br>which is specified by <code>work_dir</code> in the config file.<br>#所有的输出将会保存在工作文件夹中，<code>work_dir</code>文件在初始化文件中指定<br>By default we evaluate the model on the validation set after each epoch, you can change the evaluation interval by adding the interval argument in the training config.<br>#认情况下，我们在每个epoch之后在验证集上评估模型，您可以通过在训练配置中添加interval参数来更改评估间隔。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">evaluation = dict(interval=<span class="number">12</span>)  <span class="comment"># This evaluate the model per 12 epoch.</span></span><br></pre></td></tr></table></figure><p><strong>*Important*</strong>: The default learning rate in config files is for 8 GPUs and 2 img/gpu (batch size = 8<em>2 = 16).<br>#重要提醒，初始化文件中的学习率是针对8个GPU，2张图片每张GPU,(BATCH SIZE=8</em>2=16)<br>According to the <a href="https://arxiv.org/abs/1706.02677" target="_blank" rel="noopener">Linear Scaling Rule</a>, you need to set the learning rate proportional to the batch size if you use different GPUs or images per GPU, e.g., lr=0.01 for 4 GPUs * 2 img/gpu and lr=0.08 for 16 GPUs * 4 img/gpu.</p><h3 id="Train-with-a-single-GPU-用单个GPU训练"><a href="#Train-with-a-single-GPU-用单个GPU训练" class="headerlink" title="Train with a single GPU 用单个GPU训练"></a>Train with a single GPU 用单个GPU训练</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python tools/train.py $&#123;CONFIG_FILE&#125; [optional arguments]</span><br></pre></td></tr></table></figure><p>If you want to specify the working directory in the command, you can add an argument <code>--swork_dir ${YOUR_WORK_DIR}</code>.<br>#如果你想在命令中指定工作文件，你可以添加以下命令<code>--work_dir ${YOUR_WORK_DIR}</code></p><h3 id="Train-with-multiple-GPUs-用多个GPU训练"><a href="#Train-with-multiple-GPUs-用多个GPU训练" class="headerlink" title="Train with multiple GPUs 用多个GPU训练"></a>Train with multiple GPUs 用多个GPU训练</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./tools/dist_train.sh $&#123;CONFIG_FILE&#125; $&#123;GPU_NUM&#125; [optional arguments]</span><br></pre></td></tr></table></figure><p>Optional arguments are:</p><ul><li><code>--no-validate</code> (<strong>not suggested</strong>): By default, the codebase will perform evaluation at every k (default value is 1, which can be modified like <a href="https://github.com/open-mmlab/mmdetection/blob/master/configs/mask_rcnn/mask_rcnn_r50_fpn_1x_coco.py#L174" target="_blank" rel="noopener">this</a>) epochs during the training. To disable this behavior, use <code>--no-validate</code>.</li><li><code>--work-dir ${WORK_DIR}</code>: Override the working directory specified in the config file.</li><li><code>--resume-from ${CHECKPOINT_FILE}</code>: Resume from a previous checkpoint file.</li></ul><p>Difference between <code>resume-from</code> and <code>load-from</code>:<br><code>resume-from</code> loads both the model weights and optimizer status, and the epoch is also inherited from the specified checkpoint. It is usually used for resuming the training process that is interrupted accidentally.<br><code>load-from</code> only loads the model weights and the training epoch starts from 0. It is usually used for finetuning.</p><h3 id="Train-with-multiple-machines"><a href="#Train-with-multiple-machines" class="headerlink" title="Train with multiple machines"></a>Train with multiple machines</h3><p>If you run MMDetection on a cluster managed with <a href="https://slurm.schedmd.com/" target="_blank" rel="noopener">slurm</a>, you can use the script <code>slurm_train.sh</code>. (This script also supports single machine training.)</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[GPUS=$&#123;GPUS&#125;] ./tools/slurm_train.sh $&#123;PARTITION&#125; $&#123;JOB_NAME&#125; $&#123;CONFIG_FILE&#125; $&#123;WORK_DIR&#125;</span><br></pre></td></tr></table></figure><p>Here is an example of using 16 GPUs to train Mask R-CNN on the dev partition.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GPUS=16 ./tools/slurm_train.sh dev mask_r50_1x configs/mask_rcnn_r50_fpn_1x_coco.py /nfs/xxxx/mask_rcnn_r50_fpn_1x</span><br></pre></td></tr></table></figure><p>You can check <a href="https://github.com/open-mmlab/mmdetection/blob/master/tools/slurm_train.sh" target="_blank" rel="noopener">slurm_train.sh</a> for full arguments and environment variables.</p><p>If you have just multiple machines connected with ethernet, you can refer to<br>PyTorch <a href="https://pytorch.org/docs/stable/distributed_deprecated.html#launch-utility" target="_blank" rel="noopener">launch utility</a>.<br>Usually it is slow if you do not have high speed networking like InfiniBand.</p><h3 id="Launch-multiple-jobs-on-a-single-machine"><a href="#Launch-multiple-jobs-on-a-single-machine" class="headerlink" title="Launch multiple jobs on a single machine"></a>Launch multiple jobs on a single machine</h3><p>If you launch multiple jobs on a single machine, e.g., 2 jobs of 4-GPU training on a machine with 8 GPUs,<br>you need to specify different ports (29500 by default) for each job to avoid communication conflict.</p><p>If you use <code>dist_train.sh</code> to launch training jobs, you can set the port in commands.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=0,1,2,3 PORT=29500 ./tools/dist_train.sh $&#123;CONFIG_FILE&#125; 4</span><br><span class="line">CUDA_VISIBLE_DEVICES=4,5,6,7 PORT=29501 ./tools/dist_train.sh $&#123;CONFIG_FILE&#125; 4</span><br></pre></td></tr></table></figure><p>If you use launch training jobs with Slurm, you need to modify the config files (usually the 6th line from the bottom in config files) to set different communication ports.</p><p>In <code>config1.py</code>,</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dist_params = dict(backend=<span class="string">'nccl'</span>, port=<span class="number">29500</span>)</span><br></pre></td></tr></table></figure><p>In <code>config2.py</code>,</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dist_params = dict(backend=<span class="string">'nccl'</span>, port=<span class="number">29501</span>)</span><br></pre></td></tr></table></figure><p>Then you can launch two jobs with <code>config1.py</code> ang <code>config2.py</code>.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=0,1,2,3 GPUS=4 ./tools/slurm_train.sh $&#123;PARTITION&#125; $&#123;JOB_NAME&#125; config1.py $&#123;WORK_DIR&#125;</span><br><span class="line">CUDA_VISIBLE_DEVICES=4,5,6,7 GPUS=4 ./tools/slurm_train.sh $&#123;PARTITION&#125; $&#123;JOB_NAME&#125; config2.py $&#123;WORK_DIR&#125;</span><br></pre></td></tr></table></figure><h2 id="Useful-tools有用的工具"><a href="#Useful-tools有用的工具" class="headerlink" title="Useful tools有用的工具"></a>Useful tools有用的工具</h2><p>We provide lots of useful tools under <code>tools/</code> directory.<br>#我们提供了一些有用的工具，存放位置在<code>tools/</code>文件夹下。</p><h3 id="Analyze-logs分析记录"><a href="#Analyze-logs分析记录" class="headerlink" title="Analyze logs分析记录"></a>Analyze logs分析记录</h3><p>You can plot loss/mAP curves given a training log file. Run <code>pip install seaborn</code> first to install the dependency.<br>#你可以通过训练的日志文件来绘制loss/mAP曲线。你首先通过<code>pip install seaborn</code>安装依赖。<br><img src="../demo/loss_curve.png" alt="loss curve image"></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python tools/analyze_logs.py plot_curve [--keys $&#123;KEYS&#125;] [--title $&#123;TITLE&#125;] [--legend $&#123;LEGEND&#125;] [--backend $&#123;BACKEND&#125;] [--style $&#123;STYLE&#125;] [--out $&#123;OUT_FILE&#125;]</span><br></pre></td></tr></table></figure><p>Examples:</p><ul><li><p>Plot the classification loss of some run.<br>#绘制训练过程中的分类loss曲线。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python tools/analyze_logs.py plot_curve log.json --keys loss_cls --legend loss_cls</span><br></pre></td></tr></table></figure></li><li><p>Plot the classification and regression loss of some run, and save the figure to a pdf.<br>#绘制训练过程中的分类和回归损失，并将曲线保存为pdf文件。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python tools/analyze_logs.py plot_curve log.json --keys loss_cls loss_bbox --out losses.pdf</span><br></pre></td></tr></table></figure></li><li><p>Compare the bbox mAP of two runs in the same figure.<br>#比较两次训练日志的bbox_mAP</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python tools/analyze_logs.py plot_curve log1.json log2.json --keys bbox_mAP --legend run1 run2</span><br></pre></td></tr></table></figure></li></ul><p>You can also compute the average training speed.<br>#你也可以计算平均训练速度。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python tools/analyze_logs.py cal_train_time log.json [--include-outliers]</span><br></pre></td></tr></table></figure><p>The output is expected to be like the following.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">-----Analyze train time of work_dirs&#x2F;some_exp&#x2F;20190611_192040.log.json-----</span><br><span class="line">slowest epoch 11, average time is 1.2024</span><br><span class="line">fastest epoch 1, average time is 1.1909</span><br><span class="line">time std over epochs is 0.0028</span><br><span class="line">average iter time: 1.1959 s&#x2F;iter</span><br></pre></td></tr></table></figure><h3 id="Get-the-FLOPs-and-params-experimental-计算FLOPs和参数"><a href="#Get-the-FLOPs-and-params-experimental-计算FLOPs和参数" class="headerlink" title="Get the FLOPs and params (experimental)计算FLOPs和参数"></a>Get the FLOPs and params (experimental)计算FLOPs和参数</h3><p>We provide a script adapted from <a href="https://github.com/sovrasov/flops-counter.pytorch" target="_blank" rel="noopener">flops-counter.pytorch</a> to compute the FLOPs and params of a given model.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python tools/get_flops.py $&#123;CONFIG_FILE&#125; [--shape $&#123;INPUT_SHAPE&#125;]</span><br></pre></td></tr></table></figure><p>You will get the result like this.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line">Input shape: (3, 1280, 800)</span><br><span class="line">Flops: 239.32 GMac</span><br><span class="line">Params: 37.74 M</span><br><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br></pre></td></tr></table></figure><p><strong>Note</strong>: This tool is still experimental and we do not guarantee that the number is correct. You may well use the result for simple comparisons, but double check it before you adopt it in technical reports or papers.</p><p>(1) FLOPs are related to the input shape while parameters are not. The default input shape is (1, 3, 1280, 800).<br>(2) Some operators are not counted into FLOPs like GN and custom operators.<br>You can add support for new operators by modifying <a href="https://github.com/open-mmlab/mmdetection/blob/master/mmdet/utils/flops_counter.py" target="_blank" rel="noopener"><code>mmdet/utils/flops_counter.py</code></a>.<br>(3) The FLOPs of two-stage detectors is dependent on the number of proposals.</p><h3 id="Publish-a-model"><a href="#Publish-a-model" class="headerlink" title="Publish a model"></a>Publish a model</h3><p>Before you upload a model to AWS, you may want to<br>(1) convert model weights to CPU tensors, (2) delete the optimizer states and<br>(3) compute the hash of the checkpoint file and append the hash id to the filename.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python tools/publish_model.py $&#123;INPUT_FILENAME&#125; $&#123;OUTPUT_FILENAME&#125;</span><br></pre></td></tr></table></figure><p>E.g.,</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python tools/publish_model.py work_dirs/faster_rcnn/latest.pth faster_rcnn_r50_fpn_1x_20190801.pth</span><br></pre></td></tr></table></figure><p>The final output filename will be <code>faster_rcnn_r50_fpn_1x_20190801-{hash id}.pth</code>.</p><h3 id="Test-the-robustness-of-detectors"><a href="#Test-the-robustness-of-detectors" class="headerlink" title="Test the robustness of detectors"></a>Test the robustness of detectors</h3><p>Please refer to <a href="robustness_benchmarking.md">robustness_benchmarking.md</a>.</p><h3 id="Convert-to-ONNX-experimental"><a href="#Convert-to-ONNX-experimental" class="headerlink" title="Convert to ONNX (experimental)"></a>Convert to ONNX (experimental)</h3><p>We provide a script to convert model to <a href="https://github.com/onnx/onnx" target="_blank" rel="noopener">ONNX</a> format. The converted model could be visualized by tools like <a href="https://github.com/lutzroeder/netron" target="_blank" rel="noopener">Netron</a>.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python tools/pytorch2onnx.py $&#123;CONFIG_FILE&#125; $&#123;CHECKPOINT_FILE&#125; --out $&#123;ONNX_FILE&#125; [--shape $&#123;INPUT_SHAPE&#125;]</span><br></pre></td></tr></table></figure><p><strong>Note</strong>: This tool is still experimental. Customized operators are not supported for now. We set <code>use_torchvision=True</code> on-the-fly for <code>RoIPool</code> and <code>RoIAlign</code>.</p><h2 id="Tutorials讲解"><a href="#Tutorials讲解" class="headerlink" title="Tutorials讲解"></a>Tutorials讲解</h2><p>Currently, we provide four tutorials for users to <a href="tutorials/finetune.md">finetune models</a>, <a href="tutorials/new_dataset.md">add new dataset</a>, <a href="tutorials/data_pipeline.md">design data pipeline</a> and <a href="tutorials/new_modules.md">add new modules</a>.<br>We also provide a full description about the <a href="config.md">config system</a>.<br>当前，我们为用户提供了四个教程，分别用于[精调模型]（tutorials / finetune.md），[添加新数据集]（tutorials / new_dataset.md），[设计数据工作流]（tutorials / data_pipeline.md）和[添加新模型] 模块]（tutorials / new_modules.md）。<br>我们还提供有关[config system]（config.md）的完整说明。</p>]]></content>
      
      
      <categories>
          
          <category> mmdetection </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 翻译 </tag>
            
            <tag> s深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【MMDetection】(一):训练模型</title>
      <link href="/2020/06/10/%E3%80%90MMDetection%E3%80%91%E4%B8%80%20%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/"/>
      <url>/2020/06/10/%E3%80%90MMDetection%E3%80%91%E4%B8%80%20%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="mmdetection"><a href="#mmdetection" class="headerlink" title="mmdetection"></a>mmdetection</h1><h2 id="1-mmdetection简介"><a href="#1-mmdetection简介" class="headerlink" title="1. mmdetection简介"></a>1. mmdetection简介</h2><p>mmdetection是基于pytorch的开源对象检测工具箱，由商汤科技和香港中文大学<a href="http://mmlab.ie.cuhk.edu.hk/" target="_blank" rel="noopener">Multimedia Laboratory, CUHK</a>联合开发。</p><p>主要特性：</p><a id="more"></a><ul><li><p>模块化设计</p><p>将检测框架分解为不同的组件，并且可以通过组合不同的模块轻松构建定制的对象检测框架 。 </p></li><li><p>支持多种框架</p><p>该工具箱直接支持流行和现代的检测框架，<em>例如</em> Faster RCNN，Mask RCNN，RetinaNet等。</p></li><li><p>高效率</p><p>所有基本的bbox和mask操作都在GPU上运行。训练速度比其他代码库（包括<a href="https://github.com/facebookresearch/detectron2" target="_blank" rel="noopener">Detectron2</a>，<a href="https://github.com/facebookresearch/maskrcnn-benchmark" target="_blank" rel="noopener">maskrcnn-benchmark</a>和<a href="https://github.com/TuSimple/simpledet" target="_blank" rel="noopener">SimpleDet</a>）快或可比。</p></li><li><p>最先进</p><p>该工具箱源自<em>MMDet</em>团队开发的代码库，该团队在2018年赢得了<a href="http://cocodataset.org/#detection-leaderboard" target="_blank" rel="noopener">COCO检测挑战赛的冠军</a>，并且一直在推动它向前发展。</p><p>除了MMDetection之外，<em>MMDet</em>还发布了<a href="https://github.com/open-mmlab/mmcv" target="_blank" rel="noopener">mmcv</a>库用于计算机视觉研究，该库在很大程度上依赖于此工具箱。</p></li></ul><h2 id="2-训练Mask-RCNN过程"><a href="#2-训练Mask-RCNN过程" class="headerlink" title="2. 训练Mask-RCNN过程"></a>2. 训练Mask-RCNN过程</h2><h3 id="2-1-数据集"><a href="#2-1-数据集" class="headerlink" title="2.1 数据集"></a>2.1 数据集</h3><p>准备coco数据集，运行labelme2coco.py  </p><h3 id="2-2-修改预训练模型"><a href="#2-2-修改预训练模型" class="headerlink" title="2.2 修改预训练模型"></a>2.2 修改预训练模型</h3><p>打开changmaskrcnn.py文件</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">pretrained_weights  = torch.load(<span class="string">'checkpoints/mask_rcnn_r50_fpn_1x_coco_20200205-d4b0c5d6.pth'</span>)</span><br><span class="line"></span><br><span class="line">num_class = <span class="number">1</span> <span class="comment"># 填写要训练的种类个数，不包括背景</span></span><br><span class="line">pretrained_weights[<span class="string">'state_dict'</span>][<span class="string">'roi_head.bbox_head.fc_cls.weight'</span>].resize_(num_class+<span class="number">1</span>, <span class="number">1024</span>)</span><br><span class="line">pretrained_weights[<span class="string">'state_dict'</span>][<span class="string">'roi_head.bbox_head.fc_cls.bias'</span>].resize_(num_class+<span class="number">1</span>)</span><br><span class="line">pretrained_weights[<span class="string">'state_dict'</span>][<span class="string">'roi_head.bbox_head.fc_reg.weight'</span>].resize_(num_class*<span class="number">4</span>, <span class="number">1024</span>)</span><br><span class="line">pretrained_weights[<span class="string">'state_dict'</span>][<span class="string">'roi_head.bbox_head.fc_reg.bias'</span>].resize_(num_class*<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">torch.save(pretrained_weights, <span class="string">"mask_rcnn_r50_fpn_1x_%d.pth"</span>%num_class)</span><br></pre></td></tr></table></figure><h3 id="2-2-修改schedule-1x-py"><a href="#2-2-修改schedule-1x-py" class="headerlink" title="2.2 修改schedule_1x.py"></a>2.2 修改schedule_1x.py</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># optimizer ：优化函数配置</span></span><br><span class="line"><span class="comment"># type：优化模型（函数）</span></span><br><span class="line"><span class="comment"># lr：学习率</span></span><br><span class="line"><span class="comment"># momentum：动量</span></span><br><span class="line">optimizer = dict(type=<span class="string">'SGD'</span>, lr=<span class="number">0.02</span>, momentum=<span class="number">0.9</span>, weight_decay=<span class="number">0.0001</span>)</span><br><span class="line"></span><br><span class="line">optimizer_config = dict(grad_clip=<span class="literal">None</span>)</span><br><span class="line"><span class="comment"># learning policy</span></span><br><span class="line">lr_config = dict(</span><br><span class="line">    policy=<span class="string">'step'</span>,</span><br><span class="line">    warmup=<span class="string">'linear'</span>,</span><br><span class="line">    warmup_iters=<span class="number">500</span>,</span><br><span class="line">    warmup_ratio=<span class="number">0.001</span>,</span><br><span class="line">    step=[<span class="number">8</span>, <span class="number">11</span>])</span><br><span class="line">total_epochs = <span class="number">50</span> <span class="comment"># 训练的总epoch数</span></span><br></pre></td></tr></table></figure><h3 id="2-3-修改default-runtime-py"><a href="#2-3-修改default-runtime-py" class="headerlink" title="2.3 修改default_runtime.py"></a>2.3 修改default_runtime.py</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">checkpoint_config = dict(interval=<span class="number">1</span>) <span class="comment"># 训练多少次保存一次权重</span></span><br><span class="line"><span class="comment"># yapf:disable</span></span><br><span class="line">log_config = dict(</span><br><span class="line">    interval=<span class="number">300</span>, <span class="comment"># 填写你的val2014文件加图片数目</span></span><br><span class="line">    hooks=[</span><br><span class="line">        dict(type=<span class="string">'TextLoggerHook'</span>),</span><br><span class="line">        <span class="comment"># dict(type='TensorboardLoggerHook')</span></span><br><span class="line">    ])</span><br><span class="line"><span class="comment"># yapf:enable</span></span><br><span class="line">dist_params = dict(backend=<span class="string">'nccl'</span>)</span><br><span class="line">log_level = <span class="string">'INFO'</span></span><br><span class="line">load_from = <span class="string">'mask_rcnn_r50_fpn_1x_1.pth'</span> <span class="comment"># 生成的新的权重文件</span></span><br><span class="line">resume_from = <span class="literal">None</span></span><br><span class="line">workflow = [(<span class="string">'train'</span>, <span class="number">1</span>)]</span><br></pre></td></tr></table></figure><h3 id="2-4-修改classes"><a href="#2-4-修改classes" class="headerlink" title="2.4 修改classes"></a>2.4 修改classes</h3><ul><li><p>修改coco.py 中的classes种类名称  </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CLASSES = (<span class="string">'xl'</span>)</span><br></pre></td></tr></table></figure></li><li><p>修改mask_rcnn_r50_fpn.py中的num_classes个数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">num_classes = <span class="number">1</span> <span class="comment">#不包括背景，一共有两处</span></span><br></pre></td></tr></table></figure></li></ul><h3 id="2-5-训练"><a href="#2-5-训练" class="headerlink" title="2.5 训练"></a>2.5 训练</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python tools/train.py configs/mask_rcnn/mask_rcnn_r50_fpn_1x_coco.py</span><br></pre></td></tr></table></figure><h3 id="2-6-测试"><a href="#2-6-测试" class="headerlink" title="2.6 测试"></a>2.6 测试</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">python demo/image_demo.py demo/<span class="number">00001.j</span>pg configs/mask_rcnn/mask_rcnn_r50_fpn_1x_coco.py work_dirs/mask_rcnn_r50_fpn_1x_coco/epoch_50.pth <span class="comment"># 测试单张图片</span></span><br><span class="line">python tools/test.py configs/mask_rcnn/mask_rcnn_r50_fpn_1x_coco.py work_dirs/mask_rcnn_r50_fpn_1x_coco/epoch_50.pth --eval segm <span class="comment"># 测试语义分割的 </span></span><br><span class="line">python tools/analyze_logs.py plot_curve work_dirs/mask_rcnn_r50_fpn_1x_coco/<span class="number">20200605</span>_185330.log.json --keys bbox_mAP_50 --legend bbox_mAP_50 <span class="comment"># 绘制bbox_mAP_50的曲线</span></span><br></pre></td></tr></table></figure><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>1.【扫盲】mmdetection 2.0全家桶训练（终结版）<a href="https://www.bilibili.com/video/BV1Ht4y1y74G" target="_blank" rel="noopener">https://www.bilibili.com/video/BV1Ht4y1y74G</a></p><p>2.<a href="https://github.com/open-mmlab/mmdetection" target="_blank" rel="noopener">https://github.com/open-mmlab/mmdetection</a></p><p>3.<a href="https://mmdetection.readthedocs.io/en/v2.0.0/index.html" target="_blank" rel="noopener">https://mmdetection.readthedocs.io/en/v2.0.0/index.html</a></p>]]></content>
      
      
      <categories>
          
          <category> mmdetection </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Markdown学习笔记</title>
      <link href="/2020/06/08/Markdown%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
      <url>/2020/06/08/Markdown%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<p>这是一个Markdown的学习博客</p><a id="more"></a><h1 id="1-Markdown"><a href="#1-Markdown" class="headerlink" title="1. Markdown"></a>1. Markdown</h1><h2 id="1-1-简介"><a href="#1-1-简介" class="headerlink" title="1.1 简介"></a>1.1 简介</h2><p>阴影，高亮：<code>你好</code><br>字体颜色：<font color = 'red'></p><p>你好呀</p><p>你好呀</p><p>你好呀</p></font><p>你好呀</p><h2 id="1-2-标题"><a href="#1-2-标题" class="headerlink" title="1.2 标题"></a>1.2 标题</h2><h2 id="1-3-段落"><a href="#1-3-段落" class="headerlink" title="1.3 段落"></a>1.3 段落</h2><h2 id="1-4-图片"><a href="#1-4-图片" class="headerlink" title="1.4 图片"></a>1.4 图片</h2><center><p><img src="../Markdown%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1.png" alt="RUNOOB 图标"></p><p><img src="../Markdown%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1.png" alt="RUNOOB 图标" title="RUNOOB"></p><img src="../Markdown学习笔记/1.png" width="50%"><center><b>图一.菜鸟教程</b></center><p>菜鸟教程</p><h2 id="1-5-链接"><a href="#1-5-链接" class="headerlink" title="1.5 链接"></a>1.5 链接</h2><p>这是一个链接 <a href="https://www.runoob.com" target="_blank" rel="noopener">菜鸟教程</a></p><p><a href="https://www.runoob.com" target="_blank" rel="noopener">https://www.runoob.com</a></p>]]></content>
      
      
      <categories>
          
          <category> Markdown </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Markdown </tag>
            
            <tag> blog </tag>
            
            <tag> html </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2020/06/07/hello-world/"/>
      <url>/2020/06/07/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><a id="more"></a><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
      
      
      <categories>
          
          <category> Hexo </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 博客 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
