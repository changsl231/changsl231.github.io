<!DOCTYPE html>
<html lang="zh-Hans">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/favicon.ico">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon.ico">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon.ico">
  <link rel="mask-icon" href="/favicon.ico" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"changsl231.xyz","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"./public/search.xml"};
  </script>




  <meta name="description" content="Getting Started 开始使用mmdetectionThis page provides basic tutorials about the usage of MMDetection.For installation instructions, please see install.md.&#x2F;&#x2F;本页提供有关MMDetection用法的基本教程。&#x2F;&#x2F;关于有关安装说明，请查看文件install">
<meta property="og:type" content="article">
<meta property="og:title" content="【MMDetection】(二):getting_started.md">
<meta property="og:url" content="http://changsl231.xyz/2020/06/16/%E3%80%90MMDetection%E3%80%91%E4%BA%8C%20getting-started-md/index.html">
<meta property="og:site_name" content="留白">
<meta property="og:description" content="Getting Started 开始使用mmdetectionThis page provides basic tutorials about the usage of MMDetection.For installation instructions, please see install.md.&#x2F;&#x2F;本页提供有关MMDetection用法的基本教程。&#x2F;&#x2F;关于有关安装说明，请查看文件install">
<meta property="og:image" content="http://changsl231.xyz/2020/06/16/demo/loss_curve.png">
<meta property="article:published_time" content="2020-06-16T02:32:49.000Z">
<meta property="article:modified_time" content="2020-06-16T02:39:46.648Z">
<meta property="article:author" content="changsl231">
<meta property="article:tag" content="深度学习">
<meta property="article:tag" content="翻译">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://changsl231.xyz/2020/06/16/demo/loss_curve.png">

<link rel="canonical" href="http://changsl231.xyz/2020/06/16/%E3%80%90MMDetection%E3%80%91%E4%BA%8C%20getting-started-md/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-Hans'
  };
</script>

  <title>【MMDetection】(二):getting_started.md | 留白</title>
  


  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?6faac9aac40657143542ade36c033816";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="留白" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">留白</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">留白的博客</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

  <a href="https://github.com/changsl231" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://changsl231.xyz/2020/06/16/%E3%80%90MMDetection%E3%80%91%E4%BA%8C%20getting-started-md/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/favicon.ico">
      <meta itemprop="name" content="changsl231">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="留白">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          【MMDetection】(二):getting_started.md
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-06-16 10:32:49 / 修改时间：10:39:46" itemprop="dateCreated datePublished" datetime="2020-06-16T10:32:49+08:00">2020-06-16</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mmdetection/" itemprop="url" rel="index"><span itemprop="name">mmdetection</span></a>
                </span>
            </span>

          
            <span id="/2020/06/16/%E3%80%90MMDetection%E3%80%91%E4%BA%8C%20getting-started-md/" class="post-meta-item leancloud_visitors" data-flag-title="【MMDetection】(二):getting_started.md" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2020/06/16/%E3%80%90MMDetection%E3%80%91%E4%BA%8C%20getting-started-md/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2020/06/16/%E3%80%90MMDetection%E3%80%91%E4%BA%8C%20getting-started-md/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>16k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>15 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="Getting-Started-开始使用mmdetection"><a href="#Getting-Started-开始使用mmdetection" class="headerlink" title="Getting Started 开始使用mmdetection"></a>Getting Started 开始使用mmdetection</h1><p>This page provides basic tutorials about the usage of MMDetection.<br>For installation instructions, please see <a href="install.md">install.md</a>.<br>//本页提供有关MMDetection用法的基本教程。<br>//关于有关安装说明，请查看文件<a href="install.md">install.md</a>.</p>
<a id="more"></a>

<h2 id="Prepare-datasets-准备数据"><a href="#Prepare-datasets-准备数据" class="headerlink" title="Prepare datasets 准备数据"></a>Prepare datasets 准备数据</h2><p>It is recommended to symlink the dataset root to <code>$MMDETECTION/data</code>.<br>If your folder structure is different, you may need to change the corresponding paths in config files.<br>//建议将数据集根目录链接到<code>$MMDETECTION/data</code>。<br>//如果您的文件夹结构不同，则可能需要更改配置文件中的相应路径。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">mmdetection</span><br><span class="line">├── mmdet</span><br><span class="line">├── tools</span><br><span class="line">├── configs</span><br><span class="line">├── data</span><br><span class="line">│   ├── coco</span><br><span class="line">│   │   ├── annotations</span><br><span class="line">│   │   ├── train2017</span><br><span class="line">│   │   ├── val2017</span><br><span class="line">│   │   ├── test2017</span><br><span class="line">│   ├── cityscapes</span><br><span class="line">│   │   ├── annotations</span><br><span class="line">│   │   ├── leftImg8bit</span><br><span class="line">│   │   │   ├── train</span><br><span class="line">│   │   │   ├── val</span><br><span class="line">│   │   ├── gtFine</span><br><span class="line">│   │   │   ├── train</span><br><span class="line">│   │   │   ├── val</span><br><span class="line">│   ├── VOCdevkit</span><br><span class="line">│   │   ├── VOC2007</span><br><span class="line">│   │   ├── VOC2012</span><br></pre></td></tr></table></figure>

<p>The cityscapes annotations have to be converted into the coco format using <code>tools/convert_datasets/cityscapes.py</code>:<br>// cityspaces标注必须使用以下命令转换为coco格式：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install cityscapesscripts</span><br><span class="line">python tools/convert_datasets/cityscapes.py ./data/cityscapes --nproc 8 --out-dir ./data/cityscapes/annotations</span><br></pre></td></tr></table></figure>

<p>Currently the config files in <code>cityscapes</code> use COCO pre-trained weights to initialize.<br>You could download the pre-trained models in advance if network is unavailable or slow, otherwise it would cause errors at the beginning of training.<br>//当前，“ cityscapes”中的配置文件使用COCO预训练的权重进行初始化。<br>//如果网络不可用或速度较慢，您可以提前下载经过预先训练的模型，否则会在训练开始时导致错误。<br>For using custom datasets, please refer to <a href="tutorials/new_dataset.md">Tutorials 2: Adding New Dataset</a>.<br>//有关使用自定义数据集的信息，请参阅<a href="tutorials/new_dataset.md">Tutorials 2: Adding New Dataset</a>。</p>
<h2 id="Inference-with-pretrained-models使用预训连模型进行推理"><a href="#Inference-with-pretrained-models使用预训连模型进行推理" class="headerlink" title="Inference with pretrained models使用预训连模型进行推理"></a>Inference with pretrained models使用预训连模型进行推理</h2><p>We provide testing scripts to evaluate a whole dataset (COCO, PASCAL VOC, Cityscapes, etc.),<br>and also some high-level apis for easier integration to other projects.<br>//我们提供测试脚本来评估整个数据集（COCO，PASCAL VOC，Cityscapes等），<br>//以及一些高级api，以便更轻松地集成到其他项目。</p>
<h3 id="Test-a-dataset-测试一个数据集"><a href="#Test-a-dataset-测试一个数据集" class="headerlink" title="Test a dataset 测试一个数据集"></a>Test a dataset 测试一个数据集</h3><ul>
<li>single GPU 单GPU</li>
<li>single node multiple GPU 单节点多GPU</li>
<li>multiple node 多节点</li>
</ul>
<p>You can use the following commands to test a dataset.<br>// 你可以使用以下命令来测试数据集</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> single-gpu testing 单gpu测试</span></span><br><span class="line">python tools/test.py $&#123;CONFIG_FILE&#125; $&#123;CHECKPOINT_FILE&#125; [--out $&#123;RESULT_FILE&#125;] [--eval $&#123;EVAL_METRICS&#125;] [--show]</span><br><span class="line">    # CONFIG_FILE：初始化文件</span><br><span class="line">    # RESULT_FILE：结果文件</span><br><span class="line">    # EVAL_METRICS: 测量参数</span><br><span class="line">    # --show：是否显示</span><br><span class="line"><span class="meta">#</span><span class="bash"> multi-gpu testing 多gpu测试</span></span><br><span class="line">./tools/dist_test.sh $&#123;CONFIG_FILE&#125; $&#123;CHECKPOINT_FILE&#125; $&#123;GPU_NUM&#125; [--out $&#123;RESULT_FILE&#125;] [--eval $&#123;EVAL_METRICS&#125;]</span><br><span class="line">    # CONFIG_FILE：初始化文件</span><br><span class="line">    # GPU_NUM：GPU数量</span><br><span class="line">    # RESULT_FILE：结果文件</span><br><span class="line">    # EVAL_METRICS: 测量参数</span><br></pre></td></tr></table></figure>

<p>Optional arguments: // 可选参数</p>
<ul>
<li><code>RESULT_FILE</code>: Filename of the output results in pickle format. If not specified, the results will not be saved to a file. # 输出结果的文件名采用pickle格式。 如果未指定，结果将不会保存到文件中。</li>
<li><code>EVAL_METRICS</code>: Items to be evaluated on the results. Allowed values depend on the dataset, e.g., <code>proposal_fast</code>, <code>proposal</code>, <code>bbox</code>, <code>segm</code> are available for COCO, <code>mAP</code>, <code>recall</code> for PASCAL VOC. Cityscapes could be evaluated by <code>cityscapes</code> as well as all COCO metrics. # 测量的指标参数。coco格式数据集可以测量： <code>proposal_fast</code>, <code>proposal</code>, <code>bbox</code>, <code>segm</code>；VOC格式数据集可以测量：<code>mAP</code>, <code>recall</code>；Cityspaces格式数据集可以测试：<code>proposal_fast</code>, <code>proposal</code>, <code>bbox</code>, <code>segm</code>，<code>cityspaces</code>。</li>
<li><code>--show</code>: If specified, detection results will be plotted on the images and shown in a new window. It is only applicable to single GPU testing and used for debugging and visualization. Please make sure that GUI is available in your environment, otherwise you may encounter the error like <code>cannot connect to X server</code>.# 如果指定，检测结果将绘制在图像上并显示在新窗口中。 它仅适用于单个GPU测试，并用于调试和可视化。 请确保您的环境中可以使用GUI，否则您可能会遇到类似<code>cannot connect to X server</code>的错误。</li>
<li><code>--show-dir</code>: If specified, detection results will be plotted on the images and saved to the specified directory. It is only applicable to single GPU testing and used for debugging and visualization. You do NOT need a GUI available in your environment for using this option.#如果指定，检测结果将绘制在图像上并保存到指定目录。 它仅适用于单个GPU测试，并用于调试和可视化。 您不需要环境中可用的GUI即可使用此选项。</li>
<li><code>--show-score-thr</code>: If specified, detections with score below this threshold will be removed.#如果指定，则分数低于此阈值的检测将被删除。</li>
</ul>
<p>Examples:#例如</p>
<p>Assume that you have already downloaded the checkpoints to the directory <code>checkpoints/</code>.<br>#确保你事先已经把模型下载到了<code>checkpoints/</code>文件夹中。</p>
<ol>
<li><p>Test Faster R-CNN and visualize the results. Press any key for the next image.<br>#1.测试Faster R-CNN并显示结果。按任意按键查看下一张图片</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">python tools/test.py configs/faster_rcnn_r50_fpn_1x_coco.py \</span><br><span class="line">    checkpoints/faster_rcnn_r50_fpn_1x_20181010-3d1b3351.pth \</span><br><span class="line">    --show</span><br></pre></td></tr></table></figure>
</li>
<li><p>Test Faster R-CNN and save the painted images for latter visualization.<br>#2.测试Faster R-CNN并保存识别后的图片。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">python tools/test.py configs/faster_rcnn_r50_fpn_1x.py \</span><br><span class="line">    checkpoints/faster_rcnn_r50_fpn_1x_20181010-3d1b3351.pth \</span><br><span class="line">    --show-dir faster_rcnn_r50_fpn_1x_results</span><br></pre></td></tr></table></figure>
</li>
<li><p>Test Faster R-CNN on PASCAL VOC (without saving the test results) and evaluate the mAP.<br>#3.测试Faster R-CNN(不保存结果)，并测试mAP</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">python tools/test.py configs/pascal_voc/faster_rcnn_r50_fpn_1x_voc.py \</span><br><span class="line">    checkpoints/SOME_CHECKPOINT.pth \</span><br><span class="line">    --eval mAP</span><br></pre></td></tr></table></figure>
</li>
<li><p>Test Mask R-CNN with 8 GPUs, and evaluate the bbox and mask AP.<br>#4.用8张GPU测试Mask R-CNN，评价指标 bbox和mask AP</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">./tools/dist_test.sh configs/mask_rcnn_r50_fpn_1x_coco.py \</span><br><span class="line">    checkpoints/mask_rcnn_r50_fpn_1x_20181010-069fa190.pth \</span><br><span class="line">    8 --out results.pkl --eval bbox segm</span><br></pre></td></tr></table></figure>
</li>
<li><p>Test Mask R-CNN with 8 GPUs, and evaluate the <strong>classwise</strong> bbox and mask AP.<br>#5.用8张GPU测试Mask R-CNN,评价指标 <strong>classwise</strong>（每个类别） bbox 和 mask AP</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">./tools/dist_test.sh configs/mask_rcnn_r50_fpn_1x_coco.py \</span><br><span class="line">    checkpoints/mask_rcnn_r50_fpn_1x_20181010-069fa190.pth \</span><br><span class="line">    8 --out results.pkl --eval bbox segm --options "classwise=True"</span><br></pre></td></tr></table></figure>
</li>
<li><p>Test Mask R-CNN on COCO test-dev with 8 GPUs, and generate the json file to be submit to the official evaluation server.<br>#用8张GPU测试Mask R-CNN,生成json文件，并提交给官方服务器。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">./tools/dist_test.sh configs/mask_rcnn_r50_fpn_1x_coco.py \</span><br><span class="line">    checkpoints/mask_rcnn_r50_fpn_1x_20181010-069fa190.pth \</span><br><span class="line">    8 --format-only --options "jsonfile_prefix=./mask_rcnn_test-dev_results"</span><br></pre></td></tr></table></figure>

</li>
</ol>
<p>You will get two json files <code>mask_rcnn_test-dev_results.bbox.json</code> and <code>mask_rcnn_test-dev_results.segm.json</code>.<br>#你将会得到两个json文件<code>mask_rcnn_test-dev_results.bbox.json</code> 和 <code>mask_rcnn_test-dev_results.segm.json</code>。<br>7. Test Mask R-CNN on Cityscapes test with 8 GPUs, and generate the txt and png files to be submit to the official evaluation server.</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">./tools/dist_test.sh configs/cityscapes/mask_rcnn_r50_fpn_1x_cityscapes.py \</span><br><span class="line">    checkpoints/mask_rcnn_r50_fpn_1x_cityscapes_20200227-afe51d5a.pth \</span><br><span class="line">    8  --format-only --options "txtfile_prefix=./mask_rcnn_cityscapes_test_results"</span><br></pre></td></tr></table></figure>

<p>The generated png and txt would be under <code>./mask_rcnn_cityscapes_test_results</code> directory.</p>
<h3 id="Image-demo图片测试"><a href="#Image-demo图片测试" class="headerlink" title="Image demo图片测试"></a>Image demo图片测试</h3><p>We provide a demo script to test a single image.<br>#我们提供了一个测试单张图片的文件。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python demo/image_demo.py $&#123;IMAGE_FILE&#125; $&#123;CONFIG_FILE&#125; $&#123;CHECKPOINT_FILE&#125; [--device $&#123;GPU_ID&#125;] [--score-thr $&#123;SCORE_THR&#125;]</span><br></pre></td></tr></table></figure>

<p>Examples:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">python demo/image_demo.py demo/demo.jpg configs/faster_rcnn_r50_fpn_1x_coco.py \</span><br><span class="line">    checkpoints/faster_rcnn_r50_fpn_1x_20181010-3d1b3351.pth --device cpu</span><br></pre></td></tr></table></figure>

<h3 id="Webcam-demo网络摄像头测试"><a href="#Webcam-demo网络摄像头测试" class="headerlink" title="Webcam demo网络摄像头测试"></a>Webcam demo网络摄像头测试</h3><p>We provide a webcam demo to illustrate the results.<br>#我们提供了一个网络摄像头演示来说明结果。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python demo/webcam_demo.py $&#123;CONFIG_FILE&#125; $&#123;CHECKPOINT_FILE&#125; [--device $&#123;GPU_ID&#125;] [--camera-id $&#123;CAMERA-ID&#125;] [--score-thr $&#123;SCORE_THR&#125;]</span><br></pre></td></tr></table></figure>

<p>Examples:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">python demo/webcam_demo.py configs/faster_rcnn_r50_fpn_1x_coco.py \</span><br><span class="line">    checkpoints/faster_rcnn_r50_fpn_1x_20181010-3d1b3351.pth</span><br></pre></td></tr></table></figure>


<h3 id="High-level-APIs-for-testing-images用于测试图像的高级API"><a href="#High-level-APIs-for-testing-images用于测试图像的高级API" class="headerlink" title="High-level APIs for testing images用于测试图像的高级API"></a>High-level APIs for testing images用于测试图像的高级API</h3><h4 id="Synchronous-interface同步接口"><a href="#Synchronous-interface同步接口" class="headerlink" title="Synchronous interface同步接口"></a>Synchronous interface同步接口</h4><p>Here is an example of building the model and test given images.<br>#这是构建模型并测试给定图像的示例。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> mmdet.apis <span class="keyword">import</span> init_detector, inference_detector</span><br><span class="line"><span class="keyword">import</span> mmcv</span><br><span class="line"></span><br><span class="line">config_file = <span class="string">'configs/faster_rcnn_r50_fpn_1x_coco.py'</span></span><br><span class="line">checkpoint_file = <span class="string">'checkpoints/faster_rcnn_r50_fpn_1x_20181010-3d1b3351.pth'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># build the model from a config file and a checkpoint file</span></span><br><span class="line">model = init_detector(config_file, checkpoint_file, device=<span class="string">'cuda:0'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># test a single image and show the results</span></span><br><span class="line">img = <span class="string">'test.jpg'</span>  <span class="comment"># or img = mmcv.imread(img), which will only load it once</span></span><br><span class="line">result = inference_detector(model, img)</span><br><span class="line"><span class="comment"># visualize the results in a new window</span></span><br><span class="line">model.show_result(img, result)</span><br><span class="line"><span class="comment"># or save the visualization results to image files</span></span><br><span class="line">model.show_result(img, result, out_file=<span class="string">'result.jpg'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># test a video and show the results</span></span><br><span class="line">video = mmcv.VideoReader(<span class="string">'video.mp4'</span>)</span><br><span class="line"><span class="keyword">for</span> frame <span class="keyword">in</span> video:</span><br><span class="line">    result = inference_detector(model, frame)</span><br><span class="line">    model.show_result(frame, result, wait_time=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<p>A notebook demo can be found in <a href="https://github.com/open-mmlab/mmdetection/blob/master/demo/inference_demo.ipynb" target="_blank" rel="noopener">demo/inference_demo.ipynb</a>.</p>
<h4 id="Asynchronous-interface-supported-for-Python-3-7"><a href="#Asynchronous-interface-supported-for-Python-3-7" class="headerlink" title="Asynchronous interface - supported for Python 3.7+"></a>Asynchronous interface - supported for Python 3.7+</h4><p>#异步接口-支持Python3.7+</p>
<p>Async interface allows not to block CPU on GPU bound inference code and enables better CPU/GPU utilization for single threaded application. Inference can be done concurrently either between different input data samples or between different models of some inference pipeline.<br>#异步接口允许不阻塞GPU绑定的推理代码上的CPU，并为单线程应用程序提供更好的CPU/GPU利用率。可以在不同的输入数据样本之间或某个推理管道的不同模型之间并发地进行推理。<br>See <code>tests/async_benchmark.py</code> to compare the speed of synchronous and asynchronous interfaces.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> mmdet.apis <span class="keyword">import</span> init_detector, async_inference_detector</span><br><span class="line"><span class="keyword">from</span> mmdet.utils.contextmanagers <span class="keyword">import</span> concurrent</span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    config_file = <span class="string">'configs/faster_rcnn_r50_fpn_1x_coco.py'</span></span><br><span class="line">    checkpoint_file = <span class="string">'checkpoints/faster_rcnn_r50_fpn_1x_20181010-3d1b3351.pth'</span></span><br><span class="line">    device = <span class="string">'cuda:0'</span></span><br><span class="line">    model = init_detector(config_file, checkpoint=checkpoint_file, device=device)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># queue is used for concurrent inference of multiple images</span></span><br><span class="line">    streamqueue = asyncio.Queue()</span><br><span class="line">    <span class="comment"># queue size defines concurrency level</span></span><br><span class="line">    streamqueue_size = <span class="number">3</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> range(streamqueue_size):</span><br><span class="line">        streamqueue.put_nowait(torch.cuda.Stream(device=device))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># test a single image and show the results</span></span><br><span class="line">    img = <span class="string">'test.jpg'</span>  <span class="comment"># or img = mmcv.imread(img), which will only load it once</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">async</span> <span class="keyword">with</span> concurrent(streamqueue):</span><br><span class="line">        result = <span class="keyword">await</span> async_inference_detector(model, img)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># visualize the results in a new window</span></span><br><span class="line">    model.show_result(img, result)</span><br><span class="line">    <span class="comment"># or save the visualization results to image files</span></span><br><span class="line">    model.show_result(img, result, out_file=<span class="string">'result.jpg'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">asyncio.run(main())</span><br></pre></td></tr></table></figure>


<h2 id="Train-a-model训练一个模型"><a href="#Train-a-model训练一个模型" class="headerlink" title="Train a model训练一个模型"></a>Train a model训练一个模型</h2><p>MMDetection implements distributed training and non-distributed training,<br>which uses <code>MMDistributedDataParallel</code> and <code>MMDataParallel</code> respectively.<br>#MMDetection实施分布式培训和非分布式培训，<br>#分别使用<code>MMDistributedDataParallel</code>和<code>MMDataParallel</code>。<br>All outputs (log files and checkpoints) will be saved to the working directory,<br>which is specified by <code>work_dir</code> in the config file.<br>#所有的输出将会保存在工作文件夹中，<code>work_dir</code>文件在初始化文件中指定<br>By default we evaluate the model on the validation set after each epoch, you can change the evaluation interval by adding the interval argument in the training config.<br>#认情况下，我们在每个epoch之后在验证集上评估模型，您可以通过在训练配置中添加interval参数来更改评估间隔。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">evaluation = dict(interval=<span class="number">12</span>)  <span class="comment"># This evaluate the model per 12 epoch.</span></span><br></pre></td></tr></table></figure>

<p><strong>*Important*</strong>: The default learning rate in config files is for 8 GPUs and 2 img/gpu (batch size = 8<em>2 = 16).<br>#重要提醒，初始化文件中的学习率是针对8个GPU，2张图片每张GPU,(BATCH SIZE=8</em>2=16)<br>According to the <a href="https://arxiv.org/abs/1706.02677" target="_blank" rel="noopener">Linear Scaling Rule</a>, you need to set the learning rate proportional to the batch size if you use different GPUs or images per GPU, e.g., lr=0.01 for 4 GPUs * 2 img/gpu and lr=0.08 for 16 GPUs * 4 img/gpu.</p>
<h3 id="Train-with-a-single-GPU-用单个GPU训练"><a href="#Train-with-a-single-GPU-用单个GPU训练" class="headerlink" title="Train with a single GPU 用单个GPU训练"></a>Train with a single GPU 用单个GPU训练</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python tools/train.py $&#123;CONFIG_FILE&#125; [optional arguments]</span><br></pre></td></tr></table></figure>

<p>If you want to specify the working directory in the command, you can add an argument <code>--swork_dir ${YOUR_WORK_DIR}</code>.<br>#如果你想在命令中指定工作文件，你可以添加以下命令<code>--work_dir ${YOUR_WORK_DIR}</code></p>
<h3 id="Train-with-multiple-GPUs-用多个GPU训练"><a href="#Train-with-multiple-GPUs-用多个GPU训练" class="headerlink" title="Train with multiple GPUs 用多个GPU训练"></a>Train with multiple GPUs 用多个GPU训练</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./tools/dist_train.sh $&#123;CONFIG_FILE&#125; $&#123;GPU_NUM&#125; [optional arguments]</span><br></pre></td></tr></table></figure>

<p>Optional arguments are:</p>
<ul>
<li><code>--no-validate</code> (<strong>not suggested</strong>): By default, the codebase will perform evaluation at every k (default value is 1, which can be modified like <a href="https://github.com/open-mmlab/mmdetection/blob/master/configs/mask_rcnn/mask_rcnn_r50_fpn_1x_coco.py#L174" target="_blank" rel="noopener">this</a>) epochs during the training. To disable this behavior, use <code>--no-validate</code>.</li>
<li><code>--work-dir ${WORK_DIR}</code>: Override the working directory specified in the config file.</li>
<li><code>--resume-from ${CHECKPOINT_FILE}</code>: Resume from a previous checkpoint file.</li>
</ul>
<p>Difference between <code>resume-from</code> and <code>load-from</code>:<br><code>resume-from</code> loads both the model weights and optimizer status, and the epoch is also inherited from the specified checkpoint. It is usually used for resuming the training process that is interrupted accidentally.<br><code>load-from</code> only loads the model weights and the training epoch starts from 0. It is usually used for finetuning.</p>
<h3 id="Train-with-multiple-machines"><a href="#Train-with-multiple-machines" class="headerlink" title="Train with multiple machines"></a>Train with multiple machines</h3><p>If you run MMDetection on a cluster managed with <a href="https://slurm.schedmd.com/" target="_blank" rel="noopener">slurm</a>, you can use the script <code>slurm_train.sh</code>. (This script also supports single machine training.)</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[GPUS=$&#123;GPUS&#125;] ./tools/slurm_train.sh $&#123;PARTITION&#125; $&#123;JOB_NAME&#125; $&#123;CONFIG_FILE&#125; $&#123;WORK_DIR&#125;</span><br></pre></td></tr></table></figure>

<p>Here is an example of using 16 GPUs to train Mask R-CNN on the dev partition.</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GPUS=16 ./tools/slurm_train.sh dev mask_r50_1x configs/mask_rcnn_r50_fpn_1x_coco.py /nfs/xxxx/mask_rcnn_r50_fpn_1x</span><br></pre></td></tr></table></figure>

<p>You can check <a href="https://github.com/open-mmlab/mmdetection/blob/master/tools/slurm_train.sh" target="_blank" rel="noopener">slurm_train.sh</a> for full arguments and environment variables.</p>
<p>If you have just multiple machines connected with ethernet, you can refer to<br>PyTorch <a href="https://pytorch.org/docs/stable/distributed_deprecated.html#launch-utility" target="_blank" rel="noopener">launch utility</a>.<br>Usually it is slow if you do not have high speed networking like InfiniBand.</p>
<h3 id="Launch-multiple-jobs-on-a-single-machine"><a href="#Launch-multiple-jobs-on-a-single-machine" class="headerlink" title="Launch multiple jobs on a single machine"></a>Launch multiple jobs on a single machine</h3><p>If you launch multiple jobs on a single machine, e.g., 2 jobs of 4-GPU training on a machine with 8 GPUs,<br>you need to specify different ports (29500 by default) for each job to avoid communication conflict.</p>
<p>If you use <code>dist_train.sh</code> to launch training jobs, you can set the port in commands.</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=0,1,2,3 PORT=29500 ./tools/dist_train.sh $&#123;CONFIG_FILE&#125; 4</span><br><span class="line">CUDA_VISIBLE_DEVICES=4,5,6,7 PORT=29501 ./tools/dist_train.sh $&#123;CONFIG_FILE&#125; 4</span><br></pre></td></tr></table></figure>

<p>If you use launch training jobs with Slurm, you need to modify the config files (usually the 6th line from the bottom in config files) to set different communication ports.</p>
<p>In <code>config1.py</code>,</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dist_params = dict(backend=<span class="string">'nccl'</span>, port=<span class="number">29500</span>)</span><br></pre></td></tr></table></figure>

<p>In <code>config2.py</code>,</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dist_params = dict(backend=<span class="string">'nccl'</span>, port=<span class="number">29501</span>)</span><br></pre></td></tr></table></figure>

<p>Then you can launch two jobs with <code>config1.py</code> ang <code>config2.py</code>.</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=0,1,2,3 GPUS=4 ./tools/slurm_train.sh $&#123;PARTITION&#125; $&#123;JOB_NAME&#125; config1.py $&#123;WORK_DIR&#125;</span><br><span class="line">CUDA_VISIBLE_DEVICES=4,5,6,7 GPUS=4 ./tools/slurm_train.sh $&#123;PARTITION&#125; $&#123;JOB_NAME&#125; config2.py $&#123;WORK_DIR&#125;</span><br></pre></td></tr></table></figure>

<h2 id="Useful-tools有用的工具"><a href="#Useful-tools有用的工具" class="headerlink" title="Useful tools有用的工具"></a>Useful tools有用的工具</h2><p>We provide lots of useful tools under <code>tools/</code> directory.<br>#我们提供了一些有用的工具，存放位置在<code>tools/</code>文件夹下。</p>
<h3 id="Analyze-logs分析记录"><a href="#Analyze-logs分析记录" class="headerlink" title="Analyze logs分析记录"></a>Analyze logs分析记录</h3><p>You can plot loss/mAP curves given a training log file. Run <code>pip install seaborn</code> first to install the dependency.<br>#你可以通过训练的日志文件来绘制loss/mAP曲线。你首先通过<code>pip install seaborn</code>安装依赖。<br><img src="../demo/loss_curve.png" alt="loss curve image"></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python tools/analyze_logs.py plot_curve [--keys $&#123;KEYS&#125;] [--title $&#123;TITLE&#125;] [--legend $&#123;LEGEND&#125;] [--backend $&#123;BACKEND&#125;] [--style $&#123;STYLE&#125;] [--out $&#123;OUT_FILE&#125;]</span><br></pre></td></tr></table></figure>

<p>Examples:</p>
<ul>
<li><p>Plot the classification loss of some run.<br>#绘制训练过程中的分类loss曲线。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python tools/analyze_logs.py plot_curve log.json --keys loss_cls --legend loss_cls</span><br></pre></td></tr></table></figure>
</li>
<li><p>Plot the classification and regression loss of some run, and save the figure to a pdf.<br>#绘制训练过程中的分类和回归损失，并将曲线保存为pdf文件。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python tools/analyze_logs.py plot_curve log.json --keys loss_cls loss_bbox --out losses.pdf</span><br></pre></td></tr></table></figure>
</li>
<li><p>Compare the bbox mAP of two runs in the same figure.<br>#比较两次训练日志的bbox_mAP</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python tools/analyze_logs.py plot_curve log1.json log2.json --keys bbox_mAP --legend run1 run2</span><br></pre></td></tr></table></figure>

</li>
</ul>
<p>You can also compute the average training speed.<br>#你也可以计算平均训练速度。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python tools/analyze_logs.py cal_train_time log.json [--include-outliers]</span><br></pre></td></tr></table></figure>

<p>The output is expected to be like the following.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">-----Analyze train time of work_dirs&#x2F;some_exp&#x2F;20190611_192040.log.json-----</span><br><span class="line">slowest epoch 11, average time is 1.2024</span><br><span class="line">fastest epoch 1, average time is 1.1909</span><br><span class="line">time std over epochs is 0.0028</span><br><span class="line">average iter time: 1.1959 s&#x2F;iter</span><br></pre></td></tr></table></figure>

<h3 id="Get-the-FLOPs-and-params-experimental-计算FLOPs和参数"><a href="#Get-the-FLOPs-and-params-experimental-计算FLOPs和参数" class="headerlink" title="Get the FLOPs and params (experimental)计算FLOPs和参数"></a>Get the FLOPs and params (experimental)计算FLOPs和参数</h3><p>We provide a script adapted from <a href="https://github.com/sovrasov/flops-counter.pytorch" target="_blank" rel="noopener">flops-counter.pytorch</a> to compute the FLOPs and params of a given model.</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python tools/get_flops.py $&#123;CONFIG_FILE&#125; [--shape $&#123;INPUT_SHAPE&#125;]</span><br></pre></td></tr></table></figure>

<p>You will get the result like this.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line">Input shape: (3, 1280, 800)</span><br><span class="line">Flops: 239.32 GMac</span><br><span class="line">Params: 37.74 M</span><br><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br></pre></td></tr></table></figure>

<p><strong>Note</strong>: This tool is still experimental and we do not guarantee that the number is correct. You may well use the result for simple comparisons, but double check it before you adopt it in technical reports or papers.</p>
<p>(1) FLOPs are related to the input shape while parameters are not. The default input shape is (1, 3, 1280, 800).<br>(2) Some operators are not counted into FLOPs like GN and custom operators.<br>You can add support for new operators by modifying <a href="https://github.com/open-mmlab/mmdetection/blob/master/mmdet/utils/flops_counter.py" target="_blank" rel="noopener"><code>mmdet/utils/flops_counter.py</code></a>.<br>(3) The FLOPs of two-stage detectors is dependent on the number of proposals.</p>
<h3 id="Publish-a-model"><a href="#Publish-a-model" class="headerlink" title="Publish a model"></a>Publish a model</h3><p>Before you upload a model to AWS, you may want to<br>(1) convert model weights to CPU tensors, (2) delete the optimizer states and<br>(3) compute the hash of the checkpoint file and append the hash id to the filename.</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python tools/publish_model.py $&#123;INPUT_FILENAME&#125; $&#123;OUTPUT_FILENAME&#125;</span><br></pre></td></tr></table></figure>

<p>E.g.,</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python tools/publish_model.py work_dirs/faster_rcnn/latest.pth faster_rcnn_r50_fpn_1x_20190801.pth</span><br></pre></td></tr></table></figure>

<p>The final output filename will be <code>faster_rcnn_r50_fpn_1x_20190801-{hash id}.pth</code>.</p>
<h3 id="Test-the-robustness-of-detectors"><a href="#Test-the-robustness-of-detectors" class="headerlink" title="Test the robustness of detectors"></a>Test the robustness of detectors</h3><p>Please refer to <a href="robustness_benchmarking.md">robustness_benchmarking.md</a>.</p>
<h3 id="Convert-to-ONNX-experimental"><a href="#Convert-to-ONNX-experimental" class="headerlink" title="Convert to ONNX (experimental)"></a>Convert to ONNX (experimental)</h3><p>We provide a script to convert model to <a href="https://github.com/onnx/onnx" target="_blank" rel="noopener">ONNX</a> format. The converted model could be visualized by tools like <a href="https://github.com/lutzroeder/netron" target="_blank" rel="noopener">Netron</a>.</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python tools/pytorch2onnx.py $&#123;CONFIG_FILE&#125; $&#123;CHECKPOINT_FILE&#125; --out $&#123;ONNX_FILE&#125; [--shape $&#123;INPUT_SHAPE&#125;]</span><br></pre></td></tr></table></figure>

<p><strong>Note</strong>: This tool is still experimental. Customized operators are not supported for now. We set <code>use_torchvision=True</code> on-the-fly for <code>RoIPool</code> and <code>RoIAlign</code>.</p>
<h2 id="Tutorials讲解"><a href="#Tutorials讲解" class="headerlink" title="Tutorials讲解"></a>Tutorials讲解</h2><p>Currently, we provide four tutorials for users to <a href="tutorials/finetune.md">finetune models</a>, <a href="tutorials/new_dataset.md">add new dataset</a>, <a href="tutorials/data_pipeline.md">design data pipeline</a> and <a href="tutorials/new_modules.md">add new modules</a>.<br>We also provide a full description about the <a href="config.md">config system</a>.<br>当前，我们为用户提供了四个教程，分别用于[精调模型]（tutorials / finetune.md），[添加新数据集]（tutorials / new_dataset.md），[设计数据工作流]（tutorials / data_pipeline.md）和[添加新模型] 模块]（tutorials / new_modules.md）。<br>我们还提供有关[config system]（config.md）的完整说明。</p>

    </div>

    
    
    
        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>changsl231
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="http://changsl231.xyz/2020/06/16/%E3%80%90MMDetection%E3%80%91%E4%BA%8C%20getting-started-md/" title="【MMDetection】(二):getting_started.md">http://changsl231.xyz/2020/06/16/【MMDetection】二 getting-started-md/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>


      <div>
       
         <div>
    
        <div style="text-align:center;color: #ccc;font-size:14px;">-------------本文结束<i class="fa fa-paw"></i>感谢您的阅读-------------</div>
    
</div>
       
      </div>
	  
      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag"># 深度学习</a>
              <a href="/tags/%E7%BF%BB%E8%AF%91/" rel="tag"># 翻译</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/06/10/%E3%80%90MMDetection%E3%80%91%E4%B8%80%20%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/" rel="prev" title="【MMDetection】(一):训练模型">
      <i class="fa fa-chevron-left"></i> 【MMDetection】(一):训练模型
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/07/28/json%E4%BF%AE%E6%94%B9%E5%86%85%E5%AE%B9/" rel="next" title="修改json内容">
      修改json内容 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Getting-Started-开始使用mmdetection"><span class="nav-text">Getting Started 开始使用mmdetection</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Prepare-datasets-准备数据"><span class="nav-text">Prepare datasets 准备数据</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Inference-with-pretrained-models使用预训连模型进行推理"><span class="nav-text">Inference with pretrained models使用预训连模型进行推理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Test-a-dataset-测试一个数据集"><span class="nav-text">Test a dataset 测试一个数据集</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Image-demo图片测试"><span class="nav-text">Image demo图片测试</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Webcam-demo网络摄像头测试"><span class="nav-text">Webcam demo网络摄像头测试</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#High-level-APIs-for-testing-images用于测试图像的高级API"><span class="nav-text">High-level APIs for testing images用于测试图像的高级API</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Synchronous-interface同步接口"><span class="nav-text">Synchronous interface同步接口</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Asynchronous-interface-supported-for-Python-3-7"><span class="nav-text">Asynchronous interface - supported for Python 3.7+</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Train-a-model训练一个模型"><span class="nav-text">Train a model训练一个模型</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Train-with-a-single-GPU-用单个GPU训练"><span class="nav-text">Train with a single GPU 用单个GPU训练</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Train-with-multiple-GPUs-用多个GPU训练"><span class="nav-text">Train with multiple GPUs 用多个GPU训练</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Train-with-multiple-machines"><span class="nav-text">Train with multiple machines</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Launch-multiple-jobs-on-a-single-machine"><span class="nav-text">Launch multiple jobs on a single machine</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Useful-tools有用的工具"><span class="nav-text">Useful tools有用的工具</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Analyze-logs分析记录"><span class="nav-text">Analyze logs分析记录</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Get-the-FLOPs-and-params-experimental-计算FLOPs和参数"><span class="nav-text">Get the FLOPs and params (experimental)计算FLOPs和参数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Publish-a-model"><span class="nav-text">Publish a model</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Test-the-robustness-of-detectors"><span class="nav-text">Test the robustness of detectors</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Convert-to-ONNX-experimental"><span class="nav-text">Convert to ONNX (experimental)</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Tutorials讲解"><span class="nav-text">Tutorials讲解</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="changsl231"
      src="/favicon.ico">
  <p class="site-author-name" itemprop="name">changsl231</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">5</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">10</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">changsl231</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
    <span title="站点总字数">20k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">18 分钟</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>





        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>


  <script defer src="/lib/three/three.min.js"></script>
    <script defer src="/lib/three/canvas_lines.min.js"></script>


  




  
<script src="/js/local-search.js"></script>













  

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'OUyuhJwHyLxVCsrsONyuW1N1-gzGzoHsz',
      appKey     : 'xSfkpMdj5pTHuN08a7h7pSIk',
      placeholder: "唠两句呗",
      avatar     : 'monsterid',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : true,
      lang       : 'zh-cn' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

  
 
<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/koharu.model.json"},"display":{"position":"right","width":145,"height":320},"mobile":{"show":true,"scale":0.5},"react":{"opacityDefault":0.7,"opacityOnHover":0.8},"log":false});</script></body>
</html>
